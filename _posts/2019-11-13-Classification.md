---
layout: post
Title: Classification Project
---
This classification project gave me a data set of all of the colleges in the US, which I then had to analyze and use various algorithms to predict whether or not a college was for-profit. I was given a new data frame X that contained all of the numerical columns from the original data frame. A new variable y had been created that took the for-profit column from the data frame X and a chi-squared correlation test had been performed between the two data frames to see which factors were most correlated with whether or not a college was for profit. The most correlated factors (p-value of 0.0) were average family income, branches, faculty salary, instructional expenditure per fte, loan principle, pell grant debt, size, and tuition revenue per fte. I was unsurprised that faculty salary and family income correlated with whether or not a college was for-profit, but the fact this size was correlated surprised me. I began my analysis by doing a test-train split of the data and running a logistic regression model on the training set, which had a 90% accuracy score when applied to the test set. I then ran a K Nearest Neighbors model on the data, and found that the optimal number of nearest neighbors was 3 with an accuracy score of 90%. After this, I ran a classification report of the logistic regression model, and saw that there was a precision score of 93% for non-profit colleges, which means that 93% of colleges that were predicted as non-profit actually were non-profit, while 87% of colleges that were predicted to be for-profit were actually for-profit. The recall score of non-profit colleges was 89%, which shows that 89% of non-profit colleges were correctly predicted to be non-profit. The recall score of for-profit colleges was 91%, which means that 91% of for-profit colleges were correctly predicted to be for-profit. After the classification report, I plotted a confusion matrix of the model, which showed that 3437 non-profit schools were correctly predicted while 278 were incorrect. 2627 for-profit schools were correctly predicted, while 398 were not. I then created a comparative ROC curve of the accuracy of the logistic regression model, the naive bayes model, gradient boosting model, and the k nearest neighbors model. The gradient boosting algorithm had the best accuracy, while the naive bayes algorithm had the worst accuracy. After the ROC curve, I plotted a decision boundary to see whether there was a hard line that separated not-for-profit schools from for-profit schools, and while the boundary mostly separated the two groups of schools, it was not a perfect separation. I then imported a new type of classifier, the random forest classifier, to apply to the data. In order to analyze its accuracy, I ran a classification report, and saw that it predicted 86% of the data correctly, 91% of for-profit schools correctly, and 83% of non-profit schools correctly. 92% of the predicted non-profit schools were actually non-profit, and 91% of the predicted for-profit schools were actually for-profit. The model was pretty accurate, but not the most accurate model. I then imported another new classifier, the support vector machines classifier, to apply to the data. In order to analyze its accuracy, I ran a classification report, and saw that it predicted 93% of the data correctly, 94% of for-profit schools correctly, and 93% of non-profit schools correctly. 96% of the predicted non-profit schools were actually non-profit, and 91% of the predicted for-profit schools were actually for-profit. This model was also very accurate, but still not as accurate as the gradient boosting algorithm. After applying these two models to the data, I ran another comparative ROC curve graph using all six models (including the four in the previous graph), and saw that the gradient boosting algorithm was still the most effective algorithm, with the support vector machines algorithm close behind. I then played around with the gradient boosting algorithm, feeding it different schools' information to see if it would correctly predict whether or not they are for-profit. After doing so, I constructed an algorithm in an attempt to analyze the worst schools in the country. I created a data frame that included all the colleges and their accreditation status (a major indicator of whether or not a college is legitimate), their retention rate (a good measure of students wanting to stay there), their most common degree (a measure of how well they educate their students), and the percent of students that graduate with loans (how much they are paying for this education). I dropped every college that is accredited, and then created a ranking system based on the other three categories. Once I had created the ranking system, I chose a high (poor) ranking and found the names of every college above that ranking by locating their number within the original data frame. By this ranking system, the worst colleges were Advance Beauty Techs Academy, Connecticut Aero Tech School, MedTech Institute-Orlando Campus, Vatterott College-Fairview Heights, Massachusetts General Hospital Dietetic Internship, Mercy Hospital School of Nursing, Reading Hospital School of Health Sciences, University of Pittsburgh Medical Center-Shadyside School of Nursing, Jefferson County Dubois Area Vocational Technical Practical Nursing Program, Everest College-Arlington, Everest College-Dallas, and Covenant School of Nursing and Allied Health. Mercy Hospital School of Nursing had the worst score, with a 20% retention rate and nearly 90% of students graduating with loans. Poor colleges such as this bring into question predatory colleges and whether or not a college is predatory or not. There are many things to consider when trying to find out whether or not a college is predatory, but the biggest thing to consider would be if the college was for profit or not. A not for profit college is unlikely to be predatory because they have nothing to gain from students attending. Then, once the college is seen as for profit, the next most important aspect is to check how much money the college actually makes, and how much debt the students are placed in. If the faculty salary is extremely high but the students have exceedingly heavy loans after they graduate, which they struggle to pay off, that would indicate predatory practices. These students would likely come from families who could afford to pay some of a high tuition, but had to take out huge loans on the rest of the tuition. Also, if the faculty salary listed is significantly lower than the actual faculty salary, then it is likely that the college does not want people finding out how much money their faculty make, which indicates that they are attempting to steal from students. Of course, if the students are getting high degrees, then the college is probably giving them a good education, but if students are only graduating with associates degrees or lower, then the college is likely not focusing on the students' education and instead wants to take their money without giving them anything in return. A dead giveaway would be if the college is under investigation, especially for money-related issues or admission-related issues. Anna Helhoski's article on Nerd Wallet [here](https://www.nerdwallet.com/blog/loans/student-loans/college-choice/) discusses what you should do to determine if your college is predatory. She states that accreditation and licensing is generally a good measure of whether or not a college is predatory, but that a few predatory schools, such as ITT Tech and Corinthian, were accredited and licensed before they were exposed. She also recommends that you look to see if other schools will accept credits from that school in case you transfer away from it because if they don't it could mean that they think the school's education is invalid, and thus that the school could be predatory. In line with the previous arguments, Ms. Helhoski states that you should find out about the college's track record, especially with outcomes, as these are a big indicator of how well the college educates students. Possibly most importantly, she recommends talking with the students of the schools about their experiences. And lastly, she warns to look out for red flags, such as important information about the school being difficult to find, things seeming too good to be true, and pressure to pay. After reading Helhoski's article, I decided to read into the Corinthian schools because they had been accredited and were still found to be predatory. According to Lance Williams in his article on reveal news [here](https://www.revealnews.org/article/how-corinthian-colleges-a-for-profit-behemoth-suddenly-imploded/), the schools were sued over 100 times for fraud and were criticized for having high prices, high-pressure recruiting, and faked job-placement statistics. It was later found that the schools had illegally collected on high-interest private loans given to the students. Most of the students that attended the Corinthian schools had been young and poor, with 35% coming from household incomes of less than $10,000. These articles show how schools can be predatory and that all they are trying to do is extract as much money as possible from as many students as possible. Here is the link to my code: [here](https://github.com/HughShanno/Classification_Project)